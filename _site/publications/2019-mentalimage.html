<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="x-ua-compatible" content="ie=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="application-name" content="CMU Augmented Perception Lab" />
  <meta name="theme-color" content="#b00" />
  
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin />
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700&display=swap"
    rel="stylesheet"
  />
  
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Slab:wght@600&display=swap" rel="stylesheet">

  <link
    href="https://use.fontawesome.com/releases/v5.13.0/css/all.css"
    rel="stylesheet"
  />
  <link href="/styles.css" rel="stylesheet" />
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <link rel="shortcut icon" href="/favicon.ico" />
  <link
    rel="icon"
    type="image/png"
    href="/assets/logo-sphere-03-01.png"
    sizes="250x250"
  />

  <link
    rel="alternate"
    type="application/rss+xml"
    title="CMU Augmented Perception Lab"
    href="http://localhost:4000/feed.xml"
  />

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>The Mental Image Revealed by Gaze Tracking | CMU Augmented Perception Lab</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="The Mental Image Revealed by Gaze Tracking" />
<meta name="author" content="Xi Wang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user’s eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario." />
<meta property="og:description" content="Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user’s eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario." />
<link rel="canonical" href="http://localhost:4000/publications/2019-mentalimage.html" />
<meta property="og:url" content="http://localhost:4000/publications/2019-mentalimage.html" />
<meta property="og:site_name" content="CMU Augmented Perception Lab" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-01-26T18:34:38-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Xi Wang"},"url":"http://localhost:4000/publications/2019-mentalimage.html","description":"Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user’s eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario.","@type":"BlogPosting","headline":"The Mental Image Revealed by Gaze Tracking","dateModified":"2026-01-26T18:34:38-05:00","datePublished":"2026-01-26T18:34:38-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/publications/2019-mentalimage.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>

  <body>
    <div class="content">
      <header class="bg-white">
        <div class="w-100 mw8 ph4-l ph3 center pt2 pb4-l pb3 flex items-baseline flex flex-column flex-row-l">
        <!-- <div class="headermenu w-100 mw8 ph4-l ph3 right pt2 pb4-l pb3 flex items-baseline flex flex-column flex-row-l"> -->
        <!-- <div class="headermenu w-100 mw8 pa2 flex flex-column">           -->
          <a href="/" class="dib f2 mt4 fw6 link black hover-cmu-red">
          <!-- <a href="/" class="dib f2 mt2 fw6 link black absolute right-0 hover-cmu-red w-55 pa3 mr2"> -->
            <!-- <picture> -->
              <!-- <source  
                srcset="/assets/logo-sphere-01-01-01.svg"
                type="image/svg+xml"              
              /> -->
              <!-- <source
                srcset="/assets/logo-sphere-03-01.webp"
                type="image/webp"
              /> -->
              <!-- <source  
                srcset="/assets/logo-sphere-03-01.png"
                type="image/png"
              />
              <img 
                class="logo"
                alt="A coarsely tesselated sphere colored in shades of gray."
                class="pl2 w3"
              /> -->              
            <!-- </picture> -->
              Augmented Perception Lab
          </a>
          <!--  --><nav class="mt3 ml-auto-ns lh-copy w-auto-ns w-100 flex flex-column flex-row-ns f4 f5-ns">
            <!-- <nav class="mt2 lh-copy w-100 w-25 pa3 mr2"></nav> -->
            <div class="tc mt0-ns mt2">
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  " href="/index">Home</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  " href="/team">Team</a>
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  " href="/publications">Publications</a>
              <!-- <a
                class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  "
                href="/teaching"
                >Teaching</a
              > -->
              <a class="ml4-l ml3-m pa0-ns ph2 pv1 b black hover-cmu-red link dib  " href="/contact">Contact</a>
            </div>
          </nav>
        </div>

      </header>

      <main>
        <section>
  <div class="pv4 bg-white">
    <div class="w-100 mw8 ph4-l ph3 pv2-l pv3 center">
      <h1 class="f2 lh-title measure mt3">
        The Mental Image Revealed by Gaze Tracking
      </h1>

      

      <div class="mb2">
        
          Xi Wang,
          Andreas Ley,
          Sebastian Koch,
          David Lindlbauer,
          James Hays,
          Kenneth Holmqvist,
          Marc Alexa.
        <!-- . -->
        </div>

      <!-- <div class="flex flex-row flex-wrap items-start mt1">
       
        <div class="flex flex-column items-center mt3 mr4">
          <picture>
            <source srcset=""></source>
            <source srcset="/assets/person.png"></source>
            <img class="br-100 w3 h3 mb1" alt="Picture of Xi Wang" />
          </picture>
          <div class="black mw4 tc">Xi Wang</div>
        </div>
      
      </div> -->

      
        <div class="mt3">
          Published at
          <span class="b">
            
              <a href="https://chi2019.acm.org/" class="black underline-dot hover-cmu-red link">
            
            CHI
            2019
            </a>
          </span>
        </div>
      

      
    </div>
  </div>

  <div class="w-100 mw8 ph4-l ph3 center mt1">
    
    <img src="/assets/publications/2019-mentalimage.png" alt="Teaser image" class="mw-100" style="max-height: 600px">

    

    
    
      <h2>Abstract</h2>
      <div class="lh-copy">
        Humans involuntarily move their eyes when retrieving an image from memory. This motion is often similar to actually observing the image. We suggest to exploit this behavior as a new modality in human computer interaction, using the motion of the eyes as a descriptor of the image. Interaction requires the user's eyes to be tracked but no voluntary physical activity. We perform a controlled experiment and develop matching techniques using machine learning to investigate if images can be discriminated based on the gaze patterns recorded while users merely think about image. Our results indicate that image retrieval is possible with an accuracy significantly above chance. We also show that this result generalizes to images not used during training of the classifier and extends to uncontrolled settings in a realistic scenario.

      </div>
    

    <!-- width="400" height="240" class="thumb-video"  -->
    
    <iframe width="600" height="360" class="thumb-video mt3 mb2" src="https://www.youtube.com/embed/gaKdA51v5dg?iv_load_policy=3&amp;modestbranding=1&amp;rel=0&amp;autohide=1&amp;playsinline=1&amp;controls=1&amp;showinfo=0&amp;autoplay=0&amp;loop=0&amp;mute=1" frameborder="0" allowfullscreen>
    </iframe>   

    <!-- <li class="mt2"><a href="https://www.youtube.com/watch?v=gaKdA51v5dg" class="black link hover-cmu-red underline-dot ">
      Video: 30sec teaser
    </a></li> -->
    

    
    <h2>Materials</h2>
      <ul class="list pl0">
        
          <li class="mt2"><a href="https://dl.acm.org/doi/10.1145/3290605.3300839" class="black link hover-cmu-red underline-dot ">
            PDF
          </a></li>
        

        
          <li class="mt2"><a href="http://cybertron.cg.tu-berlin.de/xiwang/mental_imagery/retrieval.html" class="black link hover-cmu-red underline-dot ">
            Blog
          </a></li>
        

        

        
          <li class="mt2"><a href="https://www.youtube.com/watch?v=gaKdA51v5dg" class="black link hover-cmu-red underline-dot ">
            Video: 30sec teaser
          </a></li>
        

        
          <li class="mt2"><a href="https://www.youtube.com/watch?v=a7dBY_EZEUQ" class="black link hover-cmu-red underline-dot ">
            Video: Full length video
          </a></li>
        

        

        

        

        
        
      </ul>
    

    
      <h2>Bibtex</h2>
      <div class="f6 underline-dot">
        <pre>@inproceedings{Wang19 
 author = {Wang, Xi and Ley, Andreas and Koch, Sebastian and Lindlbauer, David and Hays, James and Holmqvist, Kenneth and Alexa, Marc}, 
 title = {The Mental Image Revealed by Gaze Tracking}, 
 year = {2019}, 
 isbn = {9781450359702}, 
 publisher = {Association for Computing Machinery}, 
 address = {New York, NY, USA}, 
 url = {https://doi.org/10.1145/3290605.3300839}, 
 doi = {10.1145/3290605.3300839}, 
 booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems}, 
 pages = {1–12}, 
 numpages = {12}, 
 keywords = {gaze pattern, eye tracking, mental imagery}, 
 location = {Glasgow, Scotland Uk}, 
 series = {CHI '19} 
 }</pre>
      </div>
    
    
  </div>
</section>

      </main>
    </div>

    <footer class="bt white mt5 flex-shrink-0">
      <div class="w-100 mw8 ph4-l ph3 center pv3 footerinfo">
        <ul class="list pl0">
          <li>
            <a href="/index" class="link white dib underline-dot-white hover-cmu-red mv1">Augmented Perception Lab</a>, 
            <a href="https://hcii.cmu.edu" class="link white underline-dot-white hover-cmu-red mv1">Human-Computer Interaction Institute</a>,
            <a href="https://www.cs.cmu.edu" class="link white dib underline-dot-white hover-cmu-red mv1">School of Computer Science</a>,
            <a href="https://www.cmu.edu" class="link white dib underline-dot-white hover-cmu-red mv1">Carnegie Mellon University</a>
            <!-- <span ></span>  -->
          </li>
          <li>
            <span>
            Newell Simon Hall,  5000 Forbes Ave, Pittsburgh, PA 15213, United States, <a href="/contact" class="link white dim underline-dot-white hover-cmu-red">How to find us.</a>
            </span>
          </li>
          <li class="pv1">
            <abbr title="Last build on 2026-01-26" class="white" style="list-style: height 2em; text-decoration: none;">Last update January 2026</abbr>              
          </li>
        </ul>
      </div>
    </footer>
  </body>
</html>
