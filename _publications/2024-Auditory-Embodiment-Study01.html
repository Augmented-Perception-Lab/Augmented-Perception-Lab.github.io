---
layout: publication
year: 2024
month: 11
selected: true
coming-soon: false
hidden: false
external : false
# link: https://dl.acm.org/doi/10.1145/3472749.3474750
# pdf: https://interactive-structures.org/assets//publications/2023-10-parametric-haptics/paper.pdf
title: "First or Third-Person Hearing? A Controlled Evaluation of Auditory Perspective on Embodiment and Sound Localization Performance"
authors:
  - Yi Fei Cheng
  - Laurie Heller
  - Stacey Cho
  - David Lindlbauer

# blog: https://interactive-structures.org/publications/2023-10-parametric-haptics/
# doi: 10.1145/3472749.3474750
venue_location: Seattle, WA, USA
venue_url: https://ieeeismar.org/
venue_tags:
  - IEEE ISMAR
type:
  - Conference
tags:
  - Virtual Reality
  - Auditory Perception
venue: IEEE ISMAR

#video-thumb: hiNdhJqOQ2E
#video-30sec: hiNdhJqOQ2E
#video-suppl: PIUCEdw4UqA
#video-talk-5min: l9ycUrf50TE
#video-talk-15min: l9ycUrf50TE

bibtex: "@inproceedings {Cheng2024Hearing, \n
author = {Cheng, Yi Fei and Heller, Laurie and Cho, Stacey and Lindlbauer, David}, \n
title = {First or Third-Person Hearing? A Controlled Evaluation of Auditory Perspective on Embodiment and Sound Localization Performance}, \n
year = {2024}, \n
publisher = {IEEE}, \n
keywords = {Virtual Reality, auditory perception}, \n
location = {Seattle, WA, USA}, \n
series = {ISMAR '24} \n
}"

---

Virtual Reality (VR) allows users to flexibly choose the perspective through which they interact with a synthetic environment. Users can either adopt a first-person perspective, in which they see through the eyes of their virtual avatar, or a third-person perspective, in which their viewpoint is detached from the virtual avatar. Prior research has shown that the visual perspective affects different interactions and influences core experiential factors, such as the user's sense of embodiment. However, there is limited understanding of how auditory perspective mediates user experience in immersive virtual environments. In this paper, we conducted a controlled experiment ($N=24$) on the effect of the user's auditory perspective on their performance in a sound localization task and their sense of embodiment. Our results showed that when viewing a virtual avatar from a third-person visual perspective, adopting the auditory perspective of the avatar may increase agency and self-avatar merging, even when controlling for variations in task difficulty caused by shifts in auditory perspective.  Additionally, our findings suggest that differences in auditory perspective generally have a smaller effect than differences in visual perspective. We discuss the implications of our empirical investigation of audio perspective for designing embodied auditory experiences in VR. 